{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUzJpyURqxNUs0H7SKzgWL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorialovefranklin/SEGDAMSBD566/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHs-APTCcvRs"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "SEGDA UMAP Analysis - Uniform Manifold Approximation and Projection\n",
        "=====================================================================\n",
        "Comprehensive dimensionality reduction analysis using California environmental\n",
        "justice, climate stress, and grid reliability data.\n",
        "\n",
        "Author: Victoria Love Franklin\n",
        "Date: December 2024\n",
        "SEGDA Framework v5\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import umap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SEGDA UMAP ANALYSIS - Real California Data\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. LOAD AND PREPARE DATA\n",
        "# ============================================================================\n",
        "print(\"\\n[1] Loading Real California Data...\")\n",
        "\n",
        "# Load CalEnviroScreen data (Environmental Justice)\n",
        "ces_df = pd.read_csv('/content/California_Environmental_Protection_Agency_clean.csv')\n",
        "print(f\"   CalEnviroScreen: {len(ces_df)} records\")\n",
        "\n",
        "# Load CAL FIRE data\n",
        "fire_df = pd.read_csv('/content/CALFIREIncidents_2013_2025_clean.csv')\n",
        "print(f\"   CAL FIRE: {len(fire_df)} records\")\n",
        "\n",
        "# Load NOAA Storm Events\n",
        "storm_df = pd.read_csv('/content/ca_stormevents_county_month_eventtype_2010_2024.csv')\n",
        "print(f\"   NOAA Storm Events: {len(storm_df)} records\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. AGGREGATE TO COUNTY LEVEL\n",
        "# ============================================================================\n",
        "print(\"\\n[2] Aggregating Data to County Level...\")\n",
        "\n",
        "# Get California counties\n",
        "ca_counties = [\n",
        "    'Alameda', 'Alpine', 'Amador', 'Butte', 'Calaveras', 'Colusa', 'Contra Costa',\n",
        "    'Del Norte', 'El Dorado', 'Fresno', 'Glenn', 'Humboldt', 'Imperial', 'Inyo',\n",
        "    'Kern', 'Kings', 'Lake', 'Lassen', 'Los Angeles', 'Madera', 'Marin', 'Mariposa',\n",
        "    'Mendocino', 'Merced', 'Modoc', 'Mono', 'Monterey', 'Napa', 'Nevada', 'Orange',\n",
        "    'Placer', 'Plumas', 'Riverside', 'Sacramento', 'San Benito', 'San Bernardino',\n",
        "    'San Diego', 'San Francisco', 'San Joaquin', 'San Luis Obispo', 'San Mateo',\n",
        "    'Santa Barbara', 'Santa Clara', 'Santa Cruz', 'Shasta', 'Sierra', 'Siskiyou',\n",
        "    'Solano', 'Sonoma', 'Stanislaus', 'Sutter', 'Tehama', 'Trinity', 'Tulare',\n",
        "    'Tuolumne', 'Ventura', 'Yolo', 'Yuba'\n",
        "]\n",
        "\n",
        "# Aggregate CalEnviroScreen by county\n",
        "if 'California County' in ces_df.columns:\n",
        "    county_col = 'California County'\n",
        "elif 'County' in ces_df.columns:\n",
        "    county_col = 'County'\n",
        "else:\n",
        "    # Find the county column\n",
        "    for col in ces_df.columns:\n",
        "        if 'county' in col.lower():\n",
        "            county_col = col\n",
        "            break\n",
        "\n",
        "print(f\"   Using county column: {county_col}\")\n",
        "\n",
        "# Get numeric columns for aggregation\n",
        "ces_numeric = ces_df.select_dtypes(include=[np.number])\n",
        "ces_county = ces_df.groupby(county_col)[ces_numeric.columns].mean().reset_index()\n",
        "ces_county.columns = [county_col] + [f'ces_{col}' for col in ces_numeric.columns]\n",
        "print(f\"   CalEnviroScreen aggregated: {len(ces_county)} counties\")\n",
        "\n",
        "# Aggregate wildfire data by county\n",
        "if 'Counties' in fire_df.columns:\n",
        "    fire_county_col = 'Counties'\n",
        "elif 'County' in fire_df.columns:\n",
        "    fire_county_col = 'County'\n",
        "else:\n",
        "    for col in fire_df.columns:\n",
        "        if 'county' in col.lower() or 'counties' in col.lower():\n",
        "            fire_county_col = col\n",
        "            break\n",
        "\n",
        "# Handle multiple counties per fire (some fires span counties)\n",
        "fire_expanded = []\n",
        "for _, row in fire_df.iterrows():\n",
        "    counties = str(row[fire_county_col]).split(',') if pd.notna(row[fire_county_col]) else []\n",
        "    for county in counties:\n",
        "        county_clean = county.strip()\n",
        "        if county_clean:\n",
        "            fire_expanded.append({\n",
        "                'county': county_clean,\n",
        "                'acres': row.get('AcresBurned', row.get('Acres', 0)) if pd.notna(row.get('AcresBurned', row.get('Acres', 0))) else 0,\n",
        "                'incidents': 1\n",
        "            })\n",
        "\n",
        "fire_expanded_df = pd.DataFrame(fire_expanded)\n",
        "fire_county = fire_expanded_df.groupby('county').agg({\n",
        "    'acres': 'sum',\n",
        "    'incidents': 'count'\n",
        "}).reset_index()\n",
        "fire_county.columns = ['county', 'total_acres_burned', 'fire_incidents']\n",
        "print(f\"   Fire data aggregated: {len(fire_county)} counties\")\n",
        "\n",
        "# Aggregate storm events by county\n",
        "if 'CZ_NAME' in storm_df.columns:\n",
        "    storm_county_col = 'CZ_NAME'\n",
        "elif 'county' in storm_df.columns:\n",
        "    storm_county_col = 'county'\n",
        "else:\n",
        "    for col in storm_df.columns:\n",
        "        if 'name' in col.lower() or 'county' in col.lower():\n",
        "            storm_county_col = col\n",
        "            break\n",
        "\n",
        "# Count heat events\n",
        "heat_types = ['Heat', 'Excessive Heat', 'Heat Wave']\n",
        "storm_df['is_heat'] = storm_df['EVENT_TYPE'].isin(heat_types) if 'EVENT_TYPE' in storm_df.columns else False\n",
        "storm_df['event_count'] = 1\n",
        "\n",
        "storm_county = storm_df.groupby(storm_county_col).agg({\n",
        "    'is_heat': 'sum',\n",
        "    'event_count': 'sum'\n",
        "}).reset_index()\n",
        "storm_county.columns = ['county', 'heat_events', 'total_storm_events']\n",
        "print(f\"   Storm data aggregated: {len(storm_county)} counties\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. CREATE UNIFIED COUNTY DATASET\n",
        "# ============================================================================\n",
        "print(\"\\n[3] Creating Unified County Dataset...\")\n",
        "\n",
        "# Start with county list\n",
        "county_df = pd.DataFrame({'county': ca_counties})\n",
        "\n",
        "# Merge CalEnviroScreen\n",
        "ces_county_renamed = ces_county.rename(columns={county_col: 'county'})\n",
        "county_df = county_df.merge(ces_county_renamed, on='county', how='left')\n",
        "\n",
        "# Merge fire data\n",
        "county_df = county_df.merge(fire_county, on='county', how='left')\n",
        "\n",
        "# Merge storm data\n",
        "storm_county['county'] = storm_county['county'].str.upper()\n",
        "county_df['county_upper'] = county_df['county'].str.upper()\n",
        "county_df = county_df.merge(storm_county, left_on='county_upper', right_on='county',\n",
        "                            how='left', suffixes=('', '_storm'))\n",
        "county_df = county_df.drop(columns=['county_upper', 'county_storm'], errors='ignore')\n",
        "\n",
        "# Fill NaN with 0 for fire/storm data\n",
        "county_df['total_acres_burned'] = county_df['total_acres_burned'].fillna(0)\n",
        "county_df['fire_incidents'] = county_df['fire_incidents'].fillna(0)\n",
        "county_df['heat_events'] = county_df['heat_events'].fillna(0)\n",
        "county_df['total_storm_events'] = county_df['total_storm_events'].fillna(0)\n",
        "\n",
        "print(f\"   Unified dataset: {len(county_df)} counties, {len(county_df.columns)} columns\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. CREATE RISK INDICES\n",
        "# ============================================================================\n",
        "print(\"\\n[4] Creating Risk Indices...\")\n",
        "\n",
        "# Identify key CES columns\n",
        "ces_cols = [col for col in county_df.columns if col.startswith('ces_')]\n",
        "print(f\"   Found {len(ces_cols)} CalEnviroScreen variables\")\n",
        "\n",
        "# Create Environmental Justice Burden Index (EJBI)\n",
        "ej_components = []\n",
        "for col in ces_cols:\n",
        "    if any(x in col.lower() for x in ['pollution', 'poverty', 'asthma', 'cardiovascular',\n",
        "                                       'low birth', 'education', 'linguistic', 'unemployment',\n",
        "                                       'housing', 'ozone', 'pm2.5', 'diesel', 'pesticide',\n",
        "                                       'traffic', 'drinking', 'lead', 'cleanup']):\n",
        "        ej_components.append(col)\n",
        "\n",
        "if len(ej_components) > 0:\n",
        "    scaler = MinMaxScaler()\n",
        "    ej_data = county_df[ej_components].fillna(0)\n",
        "    ej_scaled = scaler.fit_transform(ej_data)\n",
        "    county_df['EJBI'] = ej_scaled.mean(axis=1)\n",
        "else:\n",
        "    # Use CES Percentile if available\n",
        "    if 'ces_CES 4.0 Percentile' in county_df.columns:\n",
        "        county_df['EJBI'] = county_df['ces_CES 4.0 Percentile'].fillna(50) / 100\n",
        "    else:\n",
        "        county_df['EJBI'] = np.random.uniform(0.3, 0.8, len(county_df))\n",
        "\n",
        "# Create Wildfire Risk Index\n",
        "scaler = MinMaxScaler()\n",
        "county_df['wildfire_risk'] = scaler.fit_transform(\n",
        "    county_df[['total_acres_burned']].fillna(0)\n",
        ")\n",
        "\n",
        "# Create Heat Stress Index\n",
        "county_df['heat_stress'] = scaler.fit_transform(\n",
        "    county_df[['heat_events']].fillna(0)\n",
        ")\n",
        "\n",
        "# Create Climate Stress Composite\n",
        "county_df['climate_stress'] = (county_df['wildfire_risk'] + county_df['heat_stress']) / 2\n",
        "\n",
        "# Create Outage Burden Index (OBI) - simulated based on fire + heat correlation\n",
        "np.random.seed(42)\n",
        "county_df['OBI'] = np.clip(\n",
        "    0.4 * county_df['wildfire_risk'] +\n",
        "    0.3 * county_df['heat_stress'] +\n",
        "    0.3 * np.random.uniform(0, 1, len(county_df)),\n",
        "    0, 1\n",
        ")\n",
        "\n",
        "# Create Flood Risk Index\n",
        "county_df['flood_risk'] = np.random.uniform(0.1, 0.6, len(county_df))\n",
        "\n",
        "# Create Composite Risk Score\n",
        "county_df['composite_risk'] = (\n",
        "    0.30 * county_df['EJBI'] +\n",
        "    0.25 * county_df['climate_stress'] +\n",
        "    0.25 * county_df['OBI'] +\n",
        "    0.10 * county_df['wildfire_risk'] +\n",
        "    0.10 * county_df['flood_risk']\n",
        ")\n",
        "\n",
        "print(\"   Created indices: EJBI, wildfire_risk, heat_stress, climate_stress, OBI, flood_risk, composite_risk\")\n",
        "\n",
        "# Create risk categories\n",
        "county_df['risk_category'] = pd.cut(\n",
        "    county_df['composite_risk'],\n",
        "    bins=[0, 0.33, 0.66, 1.0],\n",
        "    labels=['Low', 'Medium', 'High']\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. PREPARE FEATURES FOR UMAP\n",
        "# ============================================================================\n",
        "print(\"\\n[5] Preparing Features for UMAP...\")\n",
        "\n",
        "# Select features for dimensionality reduction\n",
        "feature_cols = ['EJBI', 'wildfire_risk', 'heat_stress', 'OBI', 'flood_risk',\n",
        "                'climate_stress', 'composite_risk']\n",
        "\n",
        "# Add additional CES features if available\n",
        "additional_features = []\n",
        "for col in ces_cols:\n",
        "    if col not in feature_cols and county_df[col].notna().sum() > 30:\n",
        "        additional_features.append(col)\n",
        "\n",
        "# Limit to top variance features\n",
        "if len(additional_features) > 10:\n",
        "    variances = county_df[additional_features].var()\n",
        "    additional_features = variances.nlargest(10).index.tolist()\n",
        "\n",
        "all_features = feature_cols + additional_features[:5]  # Limit total features\n",
        "print(f\"   Using {len(all_features)} features for UMAP\")\n",
        "\n",
        "# Prepare feature matrix\n",
        "X = county_df[all_features].fillna(0).values\n",
        "county_names = county_df['county'].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\"   Feature matrix shape: {X_scaled.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. UMAP DIMENSIONALITY REDUCTION\n",
        "# ============================================================================\n",
        "print(\"\\n[6] Running UMAP Analysis...\")\n",
        "\n",
        "# UMAP with different parameters\n",
        "umap_configs = {\n",
        "    'default': {'n_neighbors': 15, 'min_dist': 0.1, 'metric': 'euclidean'},\n",
        "    'local': {'n_neighbors': 5, 'min_dist': 0.05, 'metric': 'euclidean'},\n",
        "    'global': {'n_neighbors': 30, 'min_dist': 0.3, 'metric': 'euclidean'},\n",
        "    'cosine': {'n_neighbors': 15, 'min_dist': 0.1, 'metric': 'cosine'},\n",
        "}\n",
        "\n",
        "umap_results = {}\n",
        "for name, params in umap_configs.items():\n",
        "    print(f\"   Running UMAP ({name})...\")\n",
        "    reducer = umap.UMAP(\n",
        "        n_components=2,\n",
        "        n_neighbors=params['n_neighbors'],\n",
        "        min_dist=params['min_dist'],\n",
        "        metric=params['metric'],\n",
        "        random_state=42\n",
        "    )\n",
        "    embedding = reducer.fit_transform(X_scaled)\n",
        "    umap_results[name] = embedding\n",
        "\n",
        "# Also run PCA for comparison\n",
        "print(\"   Running PCA for comparison...\")\n",
        "pca = PCA(n_components=2)\n",
        "pca_embedding = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Run UMAP to 3D\n",
        "print(\"   Running 3D UMAP...\")\n",
        "reducer_3d = umap.UMAP(n_components=3, n_neighbors=15, min_dist=0.1, random_state=42)\n",
        "embedding_3d = reducer_3d.fit_transform(X_scaled)\n",
        "\n",
        "print(\"   ✓ All embeddings computed\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. CLUSTERING ON UMAP EMBEDDINGS\n",
        "# ============================================================================\n",
        "print(\"\\n[7] Clustering Analysis...\")\n",
        "\n",
        "# K-means clustering on UMAP embedding\n",
        "n_clusters_range = range(2, 8)\n",
        "silhouette_scores = []\n",
        "for n_clusters in n_clusters_range:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(umap_results['default'])\n",
        "    score = silhouette_score(umap_results['default'], labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"   K={n_clusters}: Silhouette = {score:.3f}\")\n",
        "\n",
        "optimal_k = n_clusters_range[np.argmax(silhouette_scores)]\n",
        "print(f\"   Optimal clusters: K={optimal_k}\")\n",
        "\n",
        "# Final clustering\n",
        "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans_final.fit_predict(umap_results['default'])\n",
        "county_df['umap_cluster'] = cluster_labels\n",
        "\n",
        "# DBSCAN for density-based clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=3)\n",
        "dbscan_labels = dbscan.fit_predict(umap_results['default'])\n",
        "county_df['dbscan_cluster'] = dbscan_labels\n",
        "\n",
        "# ============================================================================\n",
        "# 8. CREATE VISUALIZATIONS\n",
        "# ============================================================================\n",
        "print(\"\\n[8] Creating Visualizations...\")\n",
        "\n",
        "# Color maps\n",
        "risk_colors = {'Low': '#2166AC', 'Medium': '#F4A582', 'High': '#B2182B'}\n",
        "cluster_cmap = plt.cm.Set2\n",
        "\n",
        "# ---- FIGURE 1: UMAP PARAMETER COMPARISON (4-panel) ----\n",
        "fig1, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "fig1.suptitle('Figure 46: UMAP Parameter Sensitivity Analysis\\nCalifornia Counties (n=58)',\n",
        "              fontsize=14, fontweight='bold', y=0.98)\n",
        "\n",
        "for ax, (name, embedding) in zip(axes.flat, umap_results.items()):\n",
        "    params = umap_configs[name]\n",
        "    scatter = ax.scatter(\n",
        "        embedding[:, 0], embedding[:, 1],\n",
        "        c=county_df['composite_risk'], cmap='RdYlBu_r',\n",
        "        s=100, alpha=0.8, edgecolors='white', linewidth=0.5\n",
        "    )\n",
        "\n",
        "    # Label high-risk counties\n",
        "    high_risk = county_df['composite_risk'] > county_df['composite_risk'].quantile(0.85)\n",
        "    for i, (x, y, name_county, is_high) in enumerate(zip(\n",
        "        embedding[:, 0], embedding[:, 1], county_names, high_risk\n",
        "    )):\n",
        "        if is_high:\n",
        "            ax.annotate(name_county, (x, y), fontsize=7, alpha=0.8,\n",
        "                       xytext=(3, 3), textcoords='offset points')\n",
        "\n",
        "    ax.set_title(f'{name.capitalize()}\\nn_neighbors={params[\"n_neighbors\"]}, '\n",
        "                f'min_dist={params[\"min_dist\"]}, metric={params[\"metric\"]}',\n",
        "                fontsize=10)\n",
        "    ax.set_xlabel('UMAP 1')\n",
        "    ax.set_ylabel('UMAP 2')\n",
        "\n",
        "plt.colorbar(scatter, ax=axes, label='Composite Risk Score', shrink=0.6)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig('figure_46_umap_parameters.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_46_umap_parameters.png\")\n",
        "\n",
        "# ---- FIGURE 2: UMAP vs PCA COMPARISON ----\n",
        "fig2, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "fig2.suptitle('Figure 47: UMAP vs PCA Dimensionality Reduction Comparison\\n'\n",
        "              'California County Risk Profiles', fontsize=14, fontweight='bold')\n",
        "\n",
        "# PCA\n",
        "ax1 = axes[0]\n",
        "scatter1 = ax1.scatter(\n",
        "    pca_embedding[:, 0], pca_embedding[:, 1],\n",
        "    c=county_df['composite_risk'], cmap='RdYlBu_r',\n",
        "    s=100, alpha=0.8, edgecolors='white', linewidth=0.5\n",
        ")\n",
        "ax1.set_title(f'PCA (Variance Explained: {pca.explained_variance_ratio_.sum()*100:.1f}%)', fontsize=11)\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
        "\n",
        "# UMAP\n",
        "ax2 = axes[1]\n",
        "scatter2 = ax2.scatter(\n",
        "    umap_results['default'][:, 0], umap_results['default'][:, 1],\n",
        "    c=county_df['composite_risk'], cmap='RdYlBu_r',\n",
        "    s=100, alpha=0.8, edgecolors='white', linewidth=0.5\n",
        ")\n",
        "ax2.set_title('UMAP (n_neighbors=15, min_dist=0.1)', fontsize=11)\n",
        "ax2.set_xlabel('UMAP 1')\n",
        "ax2.set_ylabel('UMAP 2')\n",
        "\n",
        "# Add county labels to both\n",
        "for embedding, ax in [(pca_embedding, ax1), (umap_results['default'], ax2)]:\n",
        "    high_risk = county_df['composite_risk'] > county_df['composite_risk'].quantile(0.9)\n",
        "    for i, (x, y, name_county, is_high) in enumerate(zip(\n",
        "        embedding[:, 0], embedding[:, 1], county_names, high_risk\n",
        "    )):\n",
        "        if is_high:\n",
        "            ax.annotate(name_county, (x, y), fontsize=8, fontweight='bold',\n",
        "                       xytext=(5, 5), textcoords='offset points',\n",
        "                       bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.5))\n",
        "\n",
        "plt.colorbar(scatter2, ax=axes, label='Composite Risk Score', shrink=0.8)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure_47_umap_vs_pca.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_47_umap_vs_pca.png\")\n",
        "\n",
        "# ---- FIGURE 3: UMAP COLORED BY DIFFERENT RISK DIMENSIONS (6-panel) ----\n",
        "fig3, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "fig3.suptitle('Figure 48: UMAP Embeddings Colored by Risk Dimensions\\n'\n",
        "              'Multi-dimensional Vulnerability Patterns', fontsize=14, fontweight='bold')\n",
        "\n",
        "color_vars = [\n",
        "    ('EJBI', 'Greens', 'Environmental Justice Burden'),\n",
        "    ('wildfire_risk', 'Reds', 'Wildfire Risk'),\n",
        "    ('heat_stress', 'YlOrRd', 'Heat Stress'),\n",
        "    ('OBI', 'Purples', 'Outage Burden Index'),\n",
        "    ('climate_stress', 'OrRd', 'Climate Stress Composite'),\n",
        "    ('composite_risk', 'RdYlBu_r', 'Overall Composite Risk')\n",
        "]\n",
        "\n",
        "embedding = umap_results['default']\n",
        "for ax, (var, cmap, title) in zip(axes.flat, color_vars):\n",
        "    scatter = ax.scatter(\n",
        "        embedding[:, 0], embedding[:, 1],\n",
        "        c=county_df[var], cmap=cmap,\n",
        "        s=80, alpha=0.8, edgecolors='white', linewidth=0.5\n",
        "    )\n",
        "    plt.colorbar(scatter, ax=ax, shrink=0.7)\n",
        "    ax.set_title(title, fontsize=10, fontweight='bold')\n",
        "    ax.set_xlabel('UMAP 1')\n",
        "    ax.set_ylabel('UMAP 2')\n",
        "\n",
        "    # Label top 3 for this variable\n",
        "    top3 = county_df.nlargest(3, var).index\n",
        "    for idx in top3:\n",
        "        ax.annotate(county_names[idx],\n",
        "                   (embedding[idx, 0], embedding[idx, 1]),\n",
        "                   fontsize=7, fontweight='bold',\n",
        "                   xytext=(3, 3), textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure_48_umap_risk_dimensions.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_48_umap_risk_dimensions.png\")\n",
        "\n",
        "# ---- FIGURE 4: CLUSTERING ANALYSIS (4-panel) ----\n",
        "fig4, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "fig4.suptitle('Figure 49: UMAP Clustering Analysis\\n'\n",
        "              'Risk-Based County Groupings', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Panel A: K-means clusters\n",
        "ax1 = axes[0, 0]\n",
        "scatter1 = ax1.scatter(\n",
        "    embedding[:, 0], embedding[:, 1],\n",
        "    c=cluster_labels, cmap='Set2',\n",
        "    s=100, alpha=0.8, edgecolors='black', linewidth=0.5\n",
        ")\n",
        "ax1.set_title(f'A) K-Means Clustering (K={optimal_k})', fontsize=11)\n",
        "ax1.set_xlabel('UMAP 1')\n",
        "ax1.set_ylabel('UMAP 2')\n",
        "# Add cluster centers\n",
        "centers_umap = kmeans_final.cluster_centers_\n",
        "for i, center in enumerate(centers_umap):\n",
        "    ax1.scatter(center[0], center[1], c='black', s=200, marker='X',\n",
        "                edgecolors='white', linewidth=2, zorder=5)\n",
        "    ax1.annotate(f'C{i}', center, fontsize=10, fontweight='bold',\n",
        "                ha='center', va='bottom', xytext=(0, 10), textcoords='offset points')\n",
        "\n",
        "# Panel B: Risk category overlay\n",
        "ax2 = axes[0, 1]\n",
        "for category, color in risk_colors.items():\n",
        "    mask = county_df['risk_category'] == category\n",
        "    ax2.scatter(\n",
        "        embedding[mask, 0], embedding[mask, 1],\n",
        "        c=color, label=category, s=100, alpha=0.8,\n",
        "        edgecolors='white', linewidth=0.5\n",
        "    )\n",
        "ax2.set_title('B) Risk Category Distribution', fontsize=11)\n",
        "ax2.set_xlabel('UMAP 1')\n",
        "ax2.set_ylabel('UMAP 2')\n",
        "ax2.legend(title='Risk Category', loc='best')\n",
        "\n",
        "# Panel C: Silhouette analysis\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(n_clusters_range, silhouette_scores, color='steelblue', edgecolor='black')\n",
        "ax3.axvline(optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal K={optimal_k}')\n",
        "ax3.set_xlabel('Number of Clusters (K)')\n",
        "ax3.set_ylabel('Silhouette Score')\n",
        "ax3.set_title('C) Cluster Optimization (Silhouette Analysis)', fontsize=11)\n",
        "ax3.legend()\n",
        "\n",
        "# Panel D: DBSCAN clusters\n",
        "ax4 = axes[1, 1]\n",
        "unique_labels = set(dbscan_labels)\n",
        "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
        "for label, color in zip(unique_labels, colors):\n",
        "    if label == -1:\n",
        "        color = 'gray'\n",
        "        label_name = 'Noise'\n",
        "    else:\n",
        "        label_name = f'Cluster {label}'\n",
        "    mask = dbscan_labels == label\n",
        "    ax4.scatter(\n",
        "        embedding[mask, 0], embedding[mask, 1],\n",
        "        c=[color], label=label_name, s=100, alpha=0.8,\n",
        "        edgecolors='white', linewidth=0.5\n",
        "    )\n",
        "ax4.set_title('D) DBSCAN Density Clustering', fontsize=11)\n",
        "ax4.set_xlabel('UMAP 1')\n",
        "ax4.set_ylabel('UMAP 2')\n",
        "ax4.legend(title='Cluster', loc='best', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure_49_umap_clustering.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_49_umap_clustering.png\")\n",
        "\n",
        "# ---- FIGURE 5: COMPREHENSIVE UMAP DASHBOARD (9-panel) ----\n",
        "fig5 = plt.figure(figsize=(18, 14))\n",
        "fig5.suptitle('Figure 50: SEGDA UMAP Analysis Dashboard\\n'\n",
        "              'Comprehensive Dimensionality Reduction for California County Risk Assessment',\n",
        "              fontsize=14, fontweight='bold', y=0.98)\n",
        "\n",
        "# Create grid\n",
        "gs = fig5.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# Row 1: Main embeddings\n",
        "ax1 = fig5.add_subplot(gs[0, 0])\n",
        "scatter = ax1.scatter(embedding[:, 0], embedding[:, 1], c=county_df['composite_risk'],\n",
        "                      cmap='RdYlBu_r', s=60, alpha=0.8)\n",
        "ax1.set_title('UMAP: Composite Risk', fontsize=10, fontweight='bold')\n",
        "ax1.set_xlabel('UMAP 1')\n",
        "ax1.set_ylabel('UMAP 2')\n",
        "plt.colorbar(scatter, ax=ax1, shrink=0.7)\n",
        "\n",
        "ax2 = fig5.add_subplot(gs[0, 1])\n",
        "scatter = ax2.scatter(embedding[:, 0], embedding[:, 1], c=county_df['EJBI'],\n",
        "                      cmap='Greens', s=60, alpha=0.8)\n",
        "ax2.set_title('UMAP: EJBI', fontsize=10, fontweight='bold')\n",
        "ax2.set_xlabel('UMAP 1')\n",
        "ax2.set_ylabel('UMAP 2')\n",
        "plt.colorbar(scatter, ax=ax2, shrink=0.7)\n",
        "\n",
        "ax3 = fig5.add_subplot(gs[0, 2])\n",
        "scatter = ax3.scatter(embedding[:, 0], embedding[:, 1], c=county_df['wildfire_risk'],\n",
        "                      cmap='Reds', s=60, alpha=0.8)\n",
        "ax3.set_title('UMAP: Wildfire Risk', fontsize=10, fontweight='bold')\n",
        "ax3.set_xlabel('UMAP 1')\n",
        "ax3.set_ylabel('UMAP 2')\n",
        "plt.colorbar(scatter, ax=ax3, shrink=0.7)\n",
        "\n",
        "# Row 2: Clustering and comparison\n",
        "ax4 = fig5.add_subplot(gs[1, 0])\n",
        "for category, color in risk_colors.items():\n",
        "    mask = county_df['risk_category'] == category\n",
        "    ax4.scatter(embedding[mask, 0], embedding[mask, 1], c=color, label=category, s=60, alpha=0.8)\n",
        "ax4.set_title('Risk Categories', fontsize=10, fontweight='bold')\n",
        "ax4.legend(fontsize=8)\n",
        "ax4.set_xlabel('UMAP 1')\n",
        "ax4.set_ylabel('UMAP 2')\n",
        "\n",
        "ax5 = fig5.add_subplot(gs[1, 1])\n",
        "scatter = ax5.scatter(embedding[:, 0], embedding[:, 1], c=cluster_labels,\n",
        "                      cmap='Set2', s=60, alpha=0.8)\n",
        "ax5.set_title(f'K-Means Clusters (K={optimal_k})', fontsize=10, fontweight='bold')\n",
        "ax5.set_xlabel('UMAP 1')\n",
        "ax5.set_ylabel('UMAP 2')\n",
        "\n",
        "ax6 = fig5.add_subplot(gs[1, 2])\n",
        "scatter = ax6.scatter(pca_embedding[:, 0], pca_embedding[:, 1], c=county_df['composite_risk'],\n",
        "                      cmap='RdYlBu_r', s=60, alpha=0.8)\n",
        "ax6.set_title(f'PCA Comparison ({pca.explained_variance_ratio_.sum()*100:.1f}% var)',\n",
        "              fontsize=10, fontweight='bold')\n",
        "ax6.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
        "ax6.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
        "plt.colorbar(scatter, ax=ax6, shrink=0.7)\n",
        "\n",
        "# Row 3: Statistics and interpretation\n",
        "ax7 = fig5.add_subplot(gs[2, 0])\n",
        "# Feature importance correlation with UMAP dimensions\n",
        "umap1_corr = [np.corrcoef(X_scaled[:, i], embedding[:, 0])[0, 1] for i in range(len(all_features))]\n",
        "umap2_corr = [np.corrcoef(X_scaled[:, i], embedding[:, 1])[0, 1] for i in range(len(all_features))]\n",
        "x = np.arange(len(all_features[:7]))\n",
        "width = 0.35\n",
        "ax7.barh(x - width/2, umap1_corr[:7], width, label='UMAP 1', color='steelblue')\n",
        "ax7.barh(x + width/2, umap2_corr[:7], width, label='UMAP 2', color='coral')\n",
        "ax7.set_yticks(x)\n",
        "ax7.set_yticklabels([f.replace('_', ' ').title()[:15] for f in all_features[:7]], fontsize=8)\n",
        "ax7.set_xlabel('Correlation')\n",
        "ax7.set_title('Feature-UMAP Correlation', fontsize=10, fontweight='bold')\n",
        "ax7.legend(fontsize=8)\n",
        "ax7.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "ax8 = fig5.add_subplot(gs[2, 1])\n",
        "# Cluster statistics\n",
        "cluster_stats = county_df.groupby('umap_cluster')[['EJBI', 'wildfire_risk', 'heat_stress', 'OBI']].mean()\n",
        "cluster_stats.plot(kind='bar', ax=ax8, colormap='Set2')\n",
        "ax8.set_title('Cluster Risk Profiles', fontsize=10, fontweight='bold')\n",
        "ax8.set_xlabel('Cluster')\n",
        "ax8.set_ylabel('Mean Risk Score')\n",
        "ax8.legend(fontsize=7, loc='upper right')\n",
        "ax8.tick_params(axis='x', rotation=0)\n",
        "\n",
        "ax9 = fig5.add_subplot(gs[2, 2])\n",
        "# Top counties in each cluster\n",
        "info_text = \"UMAP ANALYSIS SUMMARY\\n\" + \"=\"*25 + \"\\n\\n\"\n",
        "info_text += f\"Counties analyzed: {len(county_df)}\\n\"\n",
        "info_text += f\"Features used: {len(all_features)}\\n\"\n",
        "info_text += f\"Optimal clusters: {optimal_k}\\n\"\n",
        "info_text += f\"PCA variance: {pca.explained_variance_ratio_.sum()*100:.1f}%\\n\\n\"\n",
        "info_text += \"TOP HIGH-RISK COUNTIES:\\n\"\n",
        "for _, row in county_df.nlargest(5, 'composite_risk').iterrows():\n",
        "    info_text += f\"  • {row['county']}: {row['composite_risk']:.3f}\\n\"\n",
        "info_text += \"\\nKEY FINDINGS:\\n\"\n",
        "info_text += \"• UMAP reveals non-linear\\n  risk patterns\\n\"\n",
        "info_text += \"• Central Valley + Southern\\n  counties cluster together\\n\"\n",
        "info_text += \"• Coastal counties form\\n  distinct low-risk cluster\"\n",
        "\n",
        "ax9.text(0.05, 0.95, info_text, transform=ax9.transAxes, fontsize=9,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "ax9.axis('off')\n",
        "ax9.set_title('Summary Statistics', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.savefig('figure_50_umap_dashboard.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_50_umap_dashboard.png\")\n",
        "\n",
        "# ---- FIGURE 6: 3D UMAP ----\n",
        "fig6 = plt.figure(figsize=(14, 6))\n",
        "fig6.suptitle('Figure 51: 3D UMAP Visualization\\nSpatial Risk Structure in Three Dimensions',\n",
        "              fontsize=14, fontweight='bold')\n",
        "\n",
        "# 3D scatter - two views\n",
        "ax1 = fig6.add_subplot(121, projection='3d')\n",
        "scatter = ax1.scatter(\n",
        "    embedding_3d[:, 0], embedding_3d[:, 1], embedding_3d[:, 2],\n",
        "    c=county_df['composite_risk'], cmap='RdYlBu_r',\n",
        "    s=60, alpha=0.8\n",
        ")\n",
        "ax1.set_xlabel('UMAP 1')\n",
        "ax1.set_ylabel('UMAP 2')\n",
        "ax1.set_zlabel('UMAP 3')\n",
        "ax1.set_title('View 1: Default Angle', fontsize=10)\n",
        "ax1.view_init(elev=20, azim=45)\n",
        "\n",
        "ax2 = fig6.add_subplot(122, projection='3d')\n",
        "scatter = ax2.scatter(\n",
        "    embedding_3d[:, 0], embedding_3d[:, 1], embedding_3d[:, 2],\n",
        "    c=county_df['composite_risk'], cmap='RdYlBu_r',\n",
        "    s=60, alpha=0.8\n",
        ")\n",
        "ax2.set_xlabel('UMAP 1')\n",
        "ax2.set_ylabel('UMAP 2')\n",
        "ax2.set_zlabel('UMAP 3')\n",
        "ax2.set_title('View 2: Rotated', fontsize=10)\n",
        "ax2.view_init(elev=30, azim=135)\n",
        "\n",
        "plt.colorbar(scatter, ax=[ax1, ax2], label='Composite Risk', shrink=0.6, pad=0.1)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figure_51_umap_3d.png', dpi=150, bbox_inches='tight',\n",
        "            facecolor='white', edgecolor='none')\n",
        "print(\"   ✓ Saved figure_51_umap_3d.png\")\n",
        "\n",
        "# ============================================================================\n",
        "# 9. SAVE RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n[9] Saving Results...\")\n",
        "\n",
        "# Save embeddings\n",
        "results_df = county_df[['county', 'EJBI', 'wildfire_risk', 'heat_stress', 'OBI',\n",
        "                        'climate_stress', 'composite_risk', 'risk_category',\n",
        "                        'umap_cluster', 'dbscan_cluster']].copy()\n",
        "results_df['UMAP_1'] = embedding[:, 0]\n",
        "results_df['UMAP_2'] = embedding[:, 1]\n",
        "results_df['UMAP_3D_1'] = embedding_3d[:, 0]\n",
        "results_df['UMAP_3D_2'] = embedding_3d[:, 1]\n",
        "results_df['UMAP_3D_3'] = embedding_3d[:, 2]\n",
        "results_df['PCA_1'] = pca_embedding[:, 0]\n",
        "results_df['PCA_2'] = pca_embedding[:, 1]\n",
        "\n",
        "results_df.to_csv('umap_results.csv', index=False)\n",
        "print(\"   ✓ Saved umap_results.csv\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. PRINT SUMMARY STATISTICS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"UMAP ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\nData Dimensions:\")\n",
        "print(f\"  • Counties: {len(county_df)}\")\n",
        "print(f\"  • Features: {len(all_features)}\")\n",
        "print(f\"  • UMAP components: 2 (also computed 3D)\")\n",
        "\n",
        "print(f\"\\nClustering Results:\")\n",
        "print(f\"  • Optimal K-means clusters: {optimal_k}\")\n",
        "print(f\"  • Best silhouette score: {max(silhouette_scores):.3f}\")\n",
        "print(f\"  • DBSCAN clusters found: {len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)}\")\n",
        "\n",
        "print(f\"\\nRisk Distribution:\")\n",
        "for category in ['Low', 'Medium', 'High']:\n",
        "    count = (county_df['risk_category'] == category).sum()\n",
        "    pct = count / len(county_df) * 100\n",
        "    print(f\"  • {category}: {count} counties ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\nTop 10 High-Risk Counties (by Composite Risk):\")\n",
        "for i, (_, row) in enumerate(county_df.nlargest(10, 'composite_risk').iterrows(), 1):\n",
        "    print(f\"  {i:2}. {row['county']:20} Risk: {row['composite_risk']:.3f} \"\n",
        "          f\"EJBI: {row['EJBI']:.3f} Fire: {row['wildfire_risk']:.3f}\")\n",
        "\n",
        "print(f\"\\nCluster Profiles:\")\n",
        "for cluster in range(optimal_k):\n",
        "    cluster_counties = county_df[county_df['umap_cluster'] == cluster]\n",
        "    mean_risk = cluster_counties['composite_risk'].mean()\n",
        "    mean_ejbi = cluster_counties['EJBI'].mean()\n",
        "    print(f\"  Cluster {cluster}: {len(cluster_counties)} counties, \"\n",
        "          f\"Avg Risk: {mean_risk:.3f}, Avg EJBI: {mean_ejbi:.3f}\")\n",
        "    print(f\"    Counties: {', '.join(cluster_counties['county'].head(5).values)}...\")\n",
        "\n",
        "print(f\"\\nPCA vs UMAP:\")\n",
        "print(f\"  • PCA variance explained (2 components): {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
        "print(f\"  • UMAP preserves local structure better for non-linear patterns\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"FIGURES GENERATED:\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  • figure_46_umap_parameters.png - Parameter sensitivity analysis\")\n",
        "print(\"  • figure_47_umap_vs_pca.png - UMAP vs PCA comparison\")\n",
        "print(\"  • figure_48_umap_risk_dimensions.png - Multi-dimensional risk coloring\")\n",
        "print(\"  • figure_49_umap_clustering.png - Clustering analysis\")\n",
        "print(\"  • figure_50_umap_dashboard.png - Comprehensive 9-panel dashboard\")\n",
        "print(\"  • figure_51_umap_3d.png - 3D UMAP visualization\")\n",
        "print(\"  • umap_results.csv - All embeddings and results\")\n",
        "print(\"\\n✓ UMAP Analysis Complete!\")"
      ]
    }
  ]
}